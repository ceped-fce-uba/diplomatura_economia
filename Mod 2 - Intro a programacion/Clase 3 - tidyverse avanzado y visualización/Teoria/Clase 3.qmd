---
title: "Tidyverse avanzado y principios de visualización"
author: "Diplomatura PEEC - UBA"
format:
  html:
    embed-resources: true
    code-tools: false
    code-copy: false
    toc: true
    toc-location: left
    theme: 
      dark: misc/diseño_oscuro.scss
      light: misc/diseño_claro.scss
    fig-width: 8
    fig-height: 5
    fig-format: retina
    warning: false
    message: false
    echo: true
execute:
  freeze: auto
editor: visual
include-after-body: misc/footer.html
---

```{r}
# Cargamos paquetes clave:1
library(tidyverse)      # Data manipulation and visualization
library(lubridate)      # Date handling
library(scales)         # Better axis formatting
library(gt)             # Beautiful tables
library(plotly)         # Interactive plots
library(patchwork)      # Combine multiple plots
library(tsibble)        # Time series tibbles
library(fabletools)     # Time series toolkit
library(feasts)         # Feature extraction for time series
library(glue)           # String interpolation

# Set theme for consistent visualization
theme_set(theme_minimal(base_size = 12) + 
          theme(plot.title = element_text(face = "bold"),
                plot.subtitle = element_text(face = "italic", size = 10),
                plot.caption = element_text(size = 8, hjust = 0)))
```

## Complejizar tidyverse

Hasta el momento se ha avanzado sobre funciones que componen el paquete `tidyverse` en forma individual, pero no hemos observado esquemas que concatenen estas funciones en un **flujo de trabajo más complejos**. Este tipo de esquemas, o procesos, tienden a ser el trabajo más típico de un usuario/a en R, ya que para sintetizar grandes volumenes de información en indicadores o métricas, se requieren procesos previos sobre los datos.

### El operador pipe (%\>%) como conector fundamental

Este instrumento o herramienta es fundamental para los flujos de trabajo, ya que es el operador a través del cual se concatenan las operaciones u ordenes que están codificadas. Su esencia se encuentra en la posibilidad de realizar múltiples operaciones, de forma secuencial y velozmente, al mismo tiempo que dicho conjunto de operaciones quedan escritas en una secuencia de código. Se trata únicamente de una transformación sintáctica: nos permite ordenar el código

```{=html}
<table>
  <tr>
    <th>Pipe del Tidyverse</th>
    <th>Sin Pipe</th>
  </tr>
  <tr>
    <td>
      <pre><code class="r">
library(dplyr)
df %>% 
  group_by(category) %>% 
  summarize(media = mean(valor))
      </code></pre>
    </td>
    <td>
      <pre><code class="r">
summarize(group_by(df, category), media = mean(valor))
      </code></pre>
    </td>
  </tr>
</table>
```

## Flujo de trabajo y base de datos

En esta clase abarcaremos el análisis y la práctica de flujos más complejos con `tidyverse`, a partir del uso de una base de datos de SIPA. Para ello, se procederá a importar dicha base y contar con ella en el ambiente de R.

```{r}
SIPA <- read_csv("../../bases/base_sipa.csv", 
                 show_col_types = FALSE) %>%
  # Convert Período to proper date format immediately
  mutate(Período = ymd(Período),
         Año = year(Período),
         Mes = month(Período, label = TRUE, abbr = TRUE),
         Trimestre = quarter(Período))
```

### Explorar la base

En primer lugar, se puede observar con que variables cuenta la base.

```{r}
names(SIPA)
```

Así, dado que una columna se llama "Variable", puede observarse al interior de esta qué etiquetas aparecen y cuál la frecuencia de cada una de estas.

```{r}
table(SIPA$Variable)
```

De este modo, es posible incluir una variable de defina el año de cada observación, a fin de obtener datos que den cuenta de una frecuencia anual y no solo mensual.

```{r}
SIPA <- SIPA %>% 
  mutate(Año = year(Período))
```

La función `year()` forma parte del paquete `lubridate`, el cual es de gran utilidad para trabajar con el formato fecha de variables al interior de una base de datos. El input para `year()` es una variable de clase fecha de nuestro data set, y su output es el año al cual corresponde el input. Al mismo tiempo, como puede verse, dicha fecha se utiliza al interior de la función `mutate()`, la cual como ya se ha visto opera creando variables nuevas o reescribiendo las ya existentes en caso de indicar el mismo nombre.

Por tanto, el comando puede leerse cómo: creese una variable llamada `Año` que tenga por contenido el año de cada uno de las fechas al interior de la variable `Período`. Así, R irá fila por fila tomando como input el contenido de la variable `Perìodo` y devolviendo como output el año al cual corresponde cada uno de los valores al interior de `Período`.

Una vez que se cuenta con la variable `Año`, se procederá a estudiar diferentes cálculos posibles.

### Primera concatenación: desde el group_by()

Un primer procesamiento de utilidad refiere a la utilización de la función `group_by()`, la cual permite "iterar" algún proceso lógico para todos los valores que toma alguna variable de nuestro dataset. Por ejemplo:

```{r}
# flujo1 <- SIPA %>% 
#   group_by(Año, Variable) %>% 
#   summarise(Promedio = mean(Valor))
# 
# flujo1

```

En este caso, el objetivo está en agrupar un procesamiento determinado para cada valor que tomen las columnas `Año` y `Variable`. El procesamiento en cuestión es calcular el promedio del contenido de la columna `Valor`.

Por ende, el código puede leerse como: creese la columna `Promedio`, la cual debe contener el promedio del contenido de la columna `Valor` para cada combinación de `Año` y `Variable`.

Este tipo de cálculos generales, también pueden especificarse para algún valor, o rango de valores, de las variables para las cuales se hace el agrupamiento (en este caso `Año` y `Variable`). Por ejemplo, acotemos el cálculo solo para una de las categorías dentro de `Variables`.

```{r}
# flujo2 <- SIPA %>%
#   filter(Variable == "Empleo asalariado en el sector privado") %>% 
#   group_by(Año) %>% 
#   summarise(Promedio = mean(Valor))
# 
# flujo2
```

En este caso, se incluye un filtro para `Variable`, el cual busca acotar el cálculo para todos los casos contenidos en la categoría *"Empleo asalariado en el sector privado"*.

Por lo tanto, el código puede leerse como: calculese el promedio de la columna `Valor`, para todo el conjunto de datos que compartan el mismo valor de la columna `Año`, pero solo para la categorìa *"Empleo asalariado en el sector privado"* de la columna `Variable`.

A su vez, es importante señalar que en este tipo de procesamientos, R ordena las filas desde el valor más bajo al más alto de la primera columna, por defecto. Sin embargo, el orden puede modificarse al especificar un orden particular con la función `arrange()`. Por ejemplo:

```{r}
# flujo3 <- SIPA %>%
#   filter(Variable == "Empleo en casas particulares") %>% 
#   group_by(Año) %>% 
#   summarise(Promedio = mean(Valor)) %>% 
#   arrange(-Año)

```

En este caso, se repite el procesamiento previo, pero luego de estimar el promedio se ordena a las filas desde el mayor valor de la variable `Año` al menor. Notar que esto es así porque se especificó un `-` delante del nombre de la variable al interior de la función `arrange()`, en caso de no incluir este signo el orden irá del menor valor al mayor.

Ideas para la primera parte:

1)  Tomar series en niveles, pasarlas a logs y después visualizar
2)  

Ideas para la visualización:

1)  Mirar boxplots

Al final mostrar por encima el HTML que hizo Vladi para EPH

# PROBANDO

# Display dataset structure using gt for a nicer table

```{r}
SIPA %>%
  slice_head(n = 6) %>%
  gt() %>%
  tab_header(
    title = "SIPA Dataset Preview",
    subtitle = "First 6 rows of the employment data"
  ) %>%
  tab_style(
    style = cell_fill(color = "aliceblue"),
    locations = cells_column_labels()
  ) %>%
  fmt_number(
    columns = vars(Valor),
    decimals = 1
  ) %>%
  opt_interactive(
    use_compact_mode = TRUE,
    use_highlight = TRUE
  )
```

# More informative variable exploration

```{r}
SIPA %>%
  count(Variable) %>%
  mutate(Proportion = n / sum(n)) %>%
  arrange(desc(n)) %>%
  gt() %>%
  tab_header(
    title = "Distribution of Variable Categories",
    subtitle = "Frequency and proportion of each category"
  ) %>%
  fmt_percent(
    columns = vars(Proportion),
    decimals = 1
  ) %>%
  tab_style(
    style = cell_fill(color = "lightcyan"),
    locations = cells_body(
      columns = vars(Variable),
      rows = 1
    )
  )
```

## Advanced Tidyverse Workflows

### The pipe operator: From %\>% to \|\>

R 4.1 introduced a native pipe operator `|>` as an alternative to the magrittr pipe `%>%`. Both accomplish similar goals, but the native pipe is slightly faster and has fewer dependencies.

```{r}
# Traditional magrittr pipe
SIPA %>% 
  group_by(Año) %>%
  summarise(mean_value = mean(Valor))

# New native pipe (R 4.1+)
SIPA |> 
  group_by(Año) |>
  summarise(mean_value = mean(Valor))
```

### Grouped operations with cleaner code

Let's calculate annual averages for each variable category, using modern tidyverse functions:

```{r}
annual_averages <- SIPA |>
  group_by(Año, Variable) |>
  summarise(
    Promedio = mean(Valor),
    Mediana = median(Valor),
    Min = min(Valor),
    Max = max(Valor),
    CV = sd(Valor) / mean(Valor), # Coefficient of variation
    .groups = "drop"  # New argument to avoid group structure warnings
  ) |>
  arrange(Variable, Año)

# Display results with gt for better presentation
annual_averages |>
  filter(Año >= 2018) |>  # Focus on recent years for clarity
  gt(groupname_col = "Variable") |>  # Group by Variable
  tab_header(
    title = "Annual Economic Indicators",
    subtitle = "Summary statistics by year and indicator type"
  ) |>
  fmt_number(
    columns = vars(Promedio, Mediana, Min, Max),
    decimals = 1
  ) |>
  fmt_percent(
    columns = vars(CV),
    decimals = 1
  ) |>
  tab_style(
    style = cell_fill(color = "lightyellow"),
    locations = cells_body(
      columns = vars(Promedio),
      rows = CV > 0.1  # Highlight high-variation indicators
    )
  ) |>
  opt_interactive(
    use_search = TRUE,
    use_filters = TRUE
  )
```

### Using across() for more powerful operations

The `across()` function, introduced in dplyr 1.0.0, lets us apply the same function(s) to multiple columns:

```{r}
# Calculate summary statistics for all numeric columns by year
SIPA |>
  select(Año, Variable, Valor) |>
  filter(Variable == "Empleo asalariado en el sector privado") |>
  group_by(Año) |>
  summarise(
    across(
      Valor,
      list(
        Media = mean,
        Mediana = median,
        Desv = sd,
        Cambio = ~(last(.) / first(.)) - 1
      ),
      .names = "{.fn}"
    )
  ) |>
  gt() |>
  fmt_percent(
    columns = vars(Cambio),
    decimals = 1
  ) |>
  tab_spanner(
    label = "Annual Statistics",
    columns = vars(Media, Mediana, Desv, Cambio)
  )
```

### Using case_when() for complex recoding

Let's create economic cycle classifications based on employment trends:

```{r}
# Create cycle classification variable
SIPA |>
  filter(Variable == "Empleo asalariado en el sector privado") |>
  arrange(Período) |>
  mutate(
    change_rate = (Valor / lag(Valor) - 1) * 100,
    cycle_status = case_when(
      change_rate > 0.5 ~ "Strong Growth",
      change_rate > 0 ~ "Moderate Growth",
      change_rate > -0.5 ~ "Moderate Contraction",
      TRUE ~ "Strong Contraction"
    ),
    cycle_status = factor(cycle_status, levels = c(
      "Strong Growth", "Moderate Growth", 
      "Moderate Contraction", "Strong Contraction"
    ))
  ) |>
  filter(!is.na(cycle_status)) |>
  ggplot(aes(x = Período, y = change_rate, fill = cycle_status)) +
  geom_col() +
  scale_fill_manual(
    values = c("darkgreen", "lightgreen", "orange", "red")
  ) +
  labs(
    title = "Monthly Employment Growth Cycles",
    subtitle = "Classification based on month-to-month change rate",
    x = NULL,
    y = "Monthly Change (%)",
    fill = "Economic Cycle"
  ) +
  theme(legend.position = "bottom")
```

### Lo que aprendimos

Throughout this session, we've focused on building a critical analytical toolkit that goes beyond basic data manipulation. We've seen how:

-   The pipe operator (`%>%` and `|>`) allows for clearer, more maintainable code by creating logical data processing flows
-   Modern visualization techniques help reveal patterns in economic data that might otherwise remain hidden
-   Time series analysis provides formal methods to understand trends, seasonal patterns, and make forecasts
-   Critical economic perspectives challenge us to look beyond the surface numbers

### Recursos adicionales

Para quienes quieran profundizar en estos conceptos:

#### R y Tidyverse

-   Wickham, H., & Grolemund, G. (2023). *R for Data Science (2nd ed)*. O'Reilly Media. <https://r4ds.hadley.nz/>
-   Healy, K. (2019). *Data Visualization: A Practical Introduction*. Princeton University Press. <https://socviz.co/>

## Referencias {.unnumbered}

```{=html}
<div id="refs" class="references csl-bib-body hanging-indent">

  <div id="ref-wickham2019" class="csl-entry">
    Wickham, H., &amp; Grolemund, G. (2023). <i>R for Data Science (2nd ed)</i>. O'Reilly Media.
  </div>

  <div id="ref-tidyverse2023" class="csl-entry">
    Tidyverse. (2023, April). <i>Base vs. magrittr pipe</i>. Retrieved from <a href="https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/">https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/</a>
  </div>

  <div id="ref-dataviz" class="csl-entry">
    DataViz Inspiration. (n.d.). Retrieved from <a href="https://www.dataviz-inspiration.com/">https://www.dataviz-inspiration.com/</a>
  </div>

  <div id="ref-r-core" class="csl-entry">
    R Core Team. (2024). <i>R: A Language and Environment for Statistical Computing</i>. R Foundation for Statistical Computing, Vienna, Austria. Retrieved from <a href="https://www.R-project.org/">https://www.R-project.org/</a>
  </div>

</div>
```
